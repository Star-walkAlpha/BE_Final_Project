{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "mental_df = pd.read_csv('modified_csv_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4303/2371066292.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mental_df = mental_df.append(mental_df_copy, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Copy the first 1000 rows\n",
    "mental_df_copy = mental_df.head(1400)\n",
    "\n",
    "# Append the copied rows to the end of the DataFrame\n",
    "mental_df = mental_df.append(mental_df_copy, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4303/2371066292.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mental_df = mental_df.append(mental_df_copy, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Copy the first 1000 rows\n",
    "mental_df_copy = mental_df.head(1400)\n",
    "\n",
    "# Append the copied rows to the end of the DataFrame\n",
    "mental_df = mental_df.append(mental_df_copy, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4303/3373304353.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mental_df = mental_df.append(mental_df_copy, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Copy the first 1000 rows\n",
    "mental_df_copy = mental_df.head(3000)\n",
    "\n",
    "# Append the copied rows to the end of the DataFrame\n",
    "mental_df = mental_df.append(mental_df_copy, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4303/3373304353.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mental_df = mental_df.append(mental_df_copy, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Copy the first 1000 rows\n",
    "mental_df_copy = mental_df.head(3000)\n",
    "\n",
    "# Append the copied rows to the end of the DataFrame\n",
    "mental_df = mental_df.append(mental_df_copy, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4303/489681541.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mental_df = mental_df.append(mental_df_copy, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Copy the first 1000 rows\n",
    "mental_df_copy = mental_df.head(8000)\n",
    "\n",
    "# Append the copied rows to the end of the DataFrame\n",
    "mental_df = mental_df.append(mental_df_copy, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target set.\n",
    "y = mental_df[\"If yes, what condition(s) have you been diagnosed with?\"]\n",
    "# Define the features set.\n",
    "X = mental_df[[\"Are you self-employed?\",\n",
    "\"Do you work remotely?\",\n",
    "\"Have you had a mental health disorder in the past?\",\n",
    "\"Do you believe your productivity is ever affected by a mental health issue?\",\n",
    "\"Do you have a family history of mental illness?\",\n",
    "\"do you feel comfortable in your working environment?\",\n",
    "\"do  you feel comfortable working  with your direct supervisor(s)?\",\n",
    "\"Do you feel that your organisation takes mental health as seriously as physical health?\",\n",
    "\"Have you observed or experienced an unsupportive or badly handled response to an issue in your current workplace?\",\n",
    "\"are you stressed about your career?\",\n",
    "\"Have you ever sought treatment for a mental health issue from a mental health professional?\",\n",
    "\"How willing would you be to share with friends and family about your work stress?\",\n",
    "\"Do you currently have a mental health disorder?\",\n",
    "\"Have you observed or experienced an unsupportive or badly handled response to an issue in your current workplace?\",\n",
    "\"Did you feel that your previous employers took mental health as seriously as physical health?\",\n",
    "\"Have your previous employers provided mental health benefits?\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19633, 16)\n",
      "[ 10  65  66  67  83   1  57  32 112  56  99  86  40   3  87  91 111  27\n",
      "  12  97  96  73 120  77 110 106  63  68 115  93  53  33  18  17  45  71\n",
      "  47 101  89  55  52   5 102  23  36  79  75  58  62 100  22 127  25  28\n",
      "  84   0  20   4  54  60  98   2 107  72 116 114  42   9 117  14  21  38\n",
      "  34  50 105  88  44  49  48  16 109 124 122  90 104 113 103 121  11   6\n",
      "  78 125  92  61  70 123  82  35  81  74  59  37  76  43  39  41 126  30\n",
      "   8  95  24   7  85  26  94  15  51  31  46  69 118  29  19  80  13 119\n",
      "  64 108]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 10:03:04.551654: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-07 10:03:04.553593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-07 10:03:04.554831: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-07 10:03:04.835589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-07 10:03:04.837435: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-07 10:03:04.838784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-07 10:03:05.463915: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-07 10:03:05.465834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-07 10:03:05.467342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389/393 [============================>.] - ETA: 0s - loss: -511.4355 - accuracy: 0.0313"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 10:03:09.358940: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-07 10:03:09.360986: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-07 10:03:09.362325: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 5s 9ms/step - loss: -514.3906 - accuracy: 0.0315 - val_loss: -857.9279 - val_accuracy: 0.0290\n",
      "Epoch 2/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -1156.9139 - accuracy: 0.0317 - val_loss: -1459.4696 - val_accuracy: 0.0290\n",
      "Epoch 3/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -1750.0516 - accuracy: 0.0317 - val_loss: -2048.0730 - val_accuracy: 0.0290\n",
      "Epoch 4/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -2336.2971 - accuracy: 0.0317 - val_loss: -2634.8262 - val_accuracy: 0.0290\n",
      "Epoch 5/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -2921.0312 - accuracy: 0.0317 - val_loss: -3219.4463 - val_accuracy: 0.0290\n",
      "Epoch 6/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -3504.8167 - accuracy: 0.0317 - val_loss: -3804.3625 - val_accuracy: 0.0290\n",
      "Epoch 7/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -4087.6394 - accuracy: 0.0317 - val_loss: -4387.7676 - val_accuracy: 0.0290\n",
      "Epoch 8/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -4670.2080 - accuracy: 0.0317 - val_loss: -4971.1616 - val_accuracy: 0.0290\n",
      "Epoch 9/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -5252.4561 - accuracy: 0.0317 - val_loss: -5553.9375 - val_accuracy: 0.0290\n",
      "Epoch 10/10\n",
      "393/393 [==============================] - 3s 8ms/step - loss: -5835.2061 - accuracy: 0.0317 - val_loss: -6137.7988 - val_accuracy: 0.0290\n",
      "123/123 [==============================] - 0s 3ms/step - loss: -6146.1045 - accuracy: 0.0326\n",
      "Test loss: -6146.1044921875\n",
      "Test accuracy: 0.03259485587477684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert the y values to integers using label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define the features set.\n",
    "# Define the target set.\n",
    "y = mental_df[\"If yes, what condition(s) have you been diagnosed with?\"].values\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define the features set.\n",
    "X = mental_df[[\"Are you self-employed?\",\n",
    "\"Do you work remotely?\",\n",
    "\"Have you had a mental health disorder in the past?\",\n",
    "\"Do you believe your productivity is ever affected by a mental health issue?\",\n",
    "\"Do you have a family history of mental illness?\",\n",
    "\"do you feel comfortable in your working environment?\",\n",
    "\"do  you feel comfortable working  with your direct supervisor(s)?\",\n",
    "\"Do you feel that your organisation takes mental health as seriously as physical health?\",\n",
    "\"Have you observed or experienced an unsupportive or badly handled response to an issue in your current workplace?\",\n",
    "\"are you stressed about your career?\",\n",
    "\"Have you ever sought treatment for a mental health issue from a mental health professional?\",\n",
    "\"How willing would you be to share with friends and family about your work stress?\",\n",
    "\"Do you currently have a mental health disorder?\",\n",
    "\"Have you observed or experienced an unsupportive or badly handled response to an issue in your current workplace?\",\n",
    "\"Did you feel that your previous employers took mental health as seriously as physical health?\",\n",
    "\"Have your previous employers provided mental health benefits?\"]]\n",
    "\n",
    "# Reset the index for both X and y dataframes\n",
    "X = X.reset_index(drop=True)\n",
    "y = pd.DataFrame(y, columns=[\"Diagnosed with\"])\n",
    "\n",
    "# Check the shape of the X dataframe\n",
    "print(X.shape)\n",
    "\n",
    "# Ensure that the values in the y dataframe are compatible with your model\n",
    "print(y[\"Diagnosed with\"].unique())\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1), y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1), y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
